
* Thesis Statement
The software consists of three services:
** Order Placement Engine
*** performs
offer placement in a market according to provided guidelines
*** receives guidelines as
a set of numerical parameters representing
**** risk tolerances,
**** hedging requirements,
**** profit targets
**** a market sentiment, defined as
***** interpretations of past market events
***** policies for interpreting current market events
***** expectations regarding future market events
** Market Observer
tool for evaluating statistical queries on market events, past and present
** Network                                                             :WIP:
decentralized multimodal swarm optimization of the above guidelines
* TODO refactor offer representation:
bitfinex and btce give volume in primary, always; kraken can do either
** pay,get × amount,asset
* TODO parametrize execution feedback depth for profitability checks
** currently profitability is checked
*** in ope-filter
*** against the entire buy/sell history
* TODO normalize rawness convention
** current status
*** some methods take string arguments
*** some take values and adapt them - fix these!
** desired behavior
any method with "raw" in its name, such as post-raw-limit:
*** receives literal parameters, get inserted as-is to API requests
*** returns json object of exchange's response
* TODO Precision
** TODO Eradicate floats from all price calculations
all price manipulation must be done on integer values! this should already be
the case, but do a line-by-line audit just to be 100% certain
** TODO Switch to CL-JSON
for full control of float parsing, rather than ST-JSON's default to #'READ
** TODO Replace scalars with amount×asset where appropriate
a bit of an endeavor, but will be worthwhile. required for proper level2 depth!
** TODO Eradicate floats from all calculations
using floats for statistical calculations is tolerable, but we can do better
* TODO Book Filter
** Receives order book updates from a book-tracker
Currently these are simply entire books, but depth updates would be best.
** Receives offer status updates from a account-tracker
Offer placement and offer cancellation
** Multiple account filters!
* TODO Actor Abstraction
CSP×FSM
** DONE MVP
** macro prototype
*** TODO sample
**** input - port current gate, as-is, to imagipony defactor macro
(defactor gate ()
  ((in :initform (make-instance 'chanl:channel))
   (key :initarg :key)
   (signer :initarg :secret)))
**** sample output
** implementation data
*** machine definition
a Finite State Machine description of the actor's interaction with its channels
**** how it handles inputs
functions called on arguments received from each input
**** how it handles outputs
when it broadcasts, and what do the broadcasts contain
**** "Remote API"
i.e. how to 'control' this actor, alter its state machine, etc
*** channel(s) to which that actor listens
*** channel(s) to which that actor sends
** timing
should timing (ie, "update the order book every 8 seconds") be expressed in actors, or
is that something better left to abstract out as a separate service sending timed messages?
** crash-only design
it should be possible to kill an actor's thread at any time, and spawning the
actor's run-function again in the proper manner should resume the actor's functioning
*** initialization
**** customization of initialization
initialization specs for actors should be defined as methods on one or more of
initialize-instance, reinitialize-instance, or shared-initialize
**** default initialization
***** channels
creation of all channels necessary for the actor's functioning
 - input channels
 - broadcast channels
 - control channels - is this just a subtype of input?
right now let's create channels as early as possible, ie, :initform
***** execution
of the actor's state machine must be insured, possibly by
 - spawning a new thread for this purpose, or
 - adding a task to an execution pool
***** registration with watchdog
the new actor provides the watchdog a death predicate, and a check frequency.
*** TODO devtools
we'll need a cross-actor debugger / condition handler, and repl-like functionality
**** condition system
make the condition system and debugger function across threads, see cond.js
**** reflection / inspection
send a function to be applied to the actor (return handled by caller)
* TODO Basis Tracking - extension of balance tracking
basis tracking ≡ keep track of the last buys and sells, make sure future trades
are always profitable. perhaps have a configurable parameter that toggles
whether you can "create new positions" rather than just "close old ones"?
** recursive cost basis:
cost basis for an asset = price at which you purchased the asset, and
optionally the cost basis which was traded away for acquiring the asset
** price should account for exchange fees
(margins too narrow to help out future-you figure out wtf you meant?)
* TODO Portfolio Handling Guidelines
How the investor specifies guidelines to the automated market maker
** "risk tolerances"
how "deep" we ensure order flow profitability
** "hedging requirements"
how readily we lose balance and regain it
** "profit targets"
kinda maybe related to "risk tolerances"?
** "market sentiment"
this should perhaps be scrapped / merged into the swarm
* Exchange modularity
** Need to distinguish between:
*** knowing a market exists
**** which assets are traded
**** at what precision
**** default fee structure
**** functions for fetching specific market data
*** tracking a market
**** book tracker, current market depth
**** trades tracker, past market movements
*** participating in it
**** market + gate = ope ?
** Participation should be mediated by rate gates
* Account
** Contents:
*** exchange / gate object
**** executes commands
**** obeys rate limit
*** balance manager
**** tracks asset balances
**** handles hedging requirements and target exposures
**** reports asset balances
**** calculates liquidity allocation plan
*** offer manager
**** tracks open offers
**** routes limit orders and cancellations to the exchange
**** performs on-demand analysis on offer distributions
**** limit orders placement according to priority (ie "best" price)
*** command executor
**** translates limit orders and cancellations into API calls
**** filters out "EOrder:Insufficient funds" errors
(they'll get placed again next round)
*** offer execution tracker
**** downloads offer execution backlog
**** tracks execution of my offers
**** performs on-demand analysis on execution stream
***** emvwap, duplex and directional
***** order flow optimization
***** update offer handler
* Trades-Tracker
** Level 2 order book!
Think later of ways to do this efficiently, right now we're just interested in
the high-level so we can express statistical arbitrage rules
** Trade Direction
*** Some exchanges provide this information in the trades data
*** For exchanges that don't, we use a classifier:
**** continually tracks best few offers on the book
**** Was the last trade >= the lowest ask? -> buyer initiative
**** Was the last trade <= the highest bid? -> seller initiative
* Dumbot
** Resilience
*** Definition
How large a buy or sell we want to suvive without getting "run over"
*** Old definition - included for reference
Our buy resilience is 4BTC, we have 0.5BTC to sell, and the ask-side order book
looks like:
|     Price |     Volume |      Depth | Our Liquidity |
|-----------+------------+------------+---------------|
| 350.00000 | 0.05000000 | 0.05000000 |               |
| 350.02859 | 0.10000000 | 0.15000000 |               |
| 350.18932 | 0.87382719 |  1.0238272 |               |
| 350.71930 | 0.18990000 |  1.2137272 |               |
| 350.99999 | 0.15000000 |  1.3637272 |               |
| 351.00000 | 2.00000000 |  3.3637272 |               |
| 351.59920 | 0.39996200 |  3.7636892 |               |
We'd thus want to spread out our 0.5BTC between the best possible ask, and just
before the last ask with a depth less than our resilience. It should spread out
the orders proportionally to the depth necessary to reach each one -- thus, we
scale our available liquidity by the VOLUME AT each order,
beginning from the minimal order size (say, 0.001 BTC), and up as high as
possible. The overall goal is not to change the shape of the order book, just
increase its liquidity.
*** Resilience is now more complex
We should at least have separate resilience for each side of the order book, if
not even distinct levels of funds, each bound at different resilience levels.
** Inputs:
(for just one side of the algorithm)
*** Order book
*** Resilience
*** Funds
* TODO de-brittlify nonces
** btce's nonce code will crap out on 2015-02-18
** bitfinex's is likely at some point to overflow and break hidden offers
